# Bagging-and-Pasting

虽然有很多机器学习方法，

但是从投票的角度看，仍然不够多

需要：（底层逻辑是 ： 大数定律）

创建更多的子模型，集成更多的子模型的意见。

子模型之间不能一致！子模型之间要有差异。



## 创建差异性

如何创建差异性？

每个模型只看样本数据的一部分

==> 取样方法：放回取样，不放回取样

==> 也就是每次从 500 个样本中抽取一部分样本后，是否要从整个样本数据集中删除这些使用过的样本

==> 放回取样 = Bagging （更常用）； 不放回取样 = Pasting；

==> 其中 Bagging 不依赖于随机，若使用 Pasting 的方式的话，每个模型抽取的样本随机性会对算法最终的预测结果有一定的影响

==> 在统计学中，放回取样：bootstrap

例如：一共有 500 个样本数据；每个子模型只看 100 个样本数据

缺点：这样会使得每个子模型的准确率变低

但在集成学习中每个子模型不需要太高的准确率



### 举个例子

对于一个二分类的问题，每个子模型的准确率只有 51%（一个极端概率，只比扔硬币的正确率高 0.01 个百分比）

在理想情况下：

1. 如果我们只有 1 个子模型，整体准确率是 51%

2. 如果我们只有 3 个子模型，整体准确率：
   `3 个模型都对的概率` + `2 个模型对的概率 * 1 个模型错的概率`
   整体准确率提高了 0.05


$$
0.51^{3}+C_{3}^{2} \cdot 0.51^{2} \cdot 0.49 = 51.5\%
$$

3. 如果我们有 500 个子模型，整体正确的概率就等于所有的模型中有一半以上的模型的预测结果是正确的（因为集成学习要投票，所以加和一半以上的模型预测正确的概率），则整体准确率：
   $$
   \sum_{i=251}^{500} C_{500}^{i} \cdot 0.51^{i} \cdot 0.49^{500-i} = 65.6\%
   $$

4. 如果有 500 个子模型，每个模型的分类准确率是 60%，那么整体的正确率：

   $$
   \sum_{i=251}^{500} C_{500}^{i} \cdot 0.6^{i} \cdot 0.4^{500-i} = 99.999\%
   $$





## 代码实验 使用 Bagging

集成学习希望每个子模型的之间都尽可能地有较大的差异，若每个子模型都一模一样，那么集成学习也就没有了意义

代码可见当前文件的同目录下的 Jupyter Notebook 文件

`Note:` 但算法会受样本数据的影响，数据有可能本身存在一些问题，所以最终集成学习的效果未必会达到理想情况下的准确度
